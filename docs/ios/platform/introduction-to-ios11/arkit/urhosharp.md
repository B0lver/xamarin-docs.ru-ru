---
title: Использование ARKit с UrhoSharp в Xamarin. iOS
description: В этом документе описывается настройка приложения ARKit в Xamarin. iOS, а также рассматриваются способы подготовки кадров, Настройка камеры, определение плоскостей, работа с освещением и многое другое. Здесь также обсуждаются UrhoSharp и написание кода для HoloLens.
ms.prod: xamarin
ms.assetid: 877AF974-CC2E-48A2-8E1A-0EF9ABF2C92D
ms.technology: xamarin-ios
author: lobrien
ms.author: laobri
ms.date: 08/01/2017
ms.openlocfilehash: 106d6100d373c8d14a35aaee59035cf4a98083a5
ms.sourcegitcommit: 6264fb540ca1f131328707e295e7259cb10f95fb
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/16/2019
ms.locfileid: "69528250"
---
# <a name="using-arkit-with-urhosharp-in-xamarinios"></a>Использование ARKit с UrhoSharp в Xamarin. iOS

С появлением [ARKit](https://developer.apple.com/arkit/)компания Apple предоставила разработчикам простой способ создания приложений, дополненных к реальности. ARKit может отслеживать точное расположение устройства и обнаруживать различные поверхности в мире, а затем до того, как разработчик сможет смешивать данные, поступающие из ARKit в код.

[UrhoSharp](~/graphics-games/urhosharp/index.md) предоставляет исчерпывающий и простой в использовании трехмерный API, который можно использовать для создания трехмерных приложений.   Оба этих варианта можно объединить, ARKit, чтобы предоставить физическую информацию о мире и Урхо для визуализации результатов.

На этой странице объясняется, как подключить эти две мировые приложения для создания качественных приложений в реальных условиях.

## <a name="the-basics"></a>Основы

Мы хотим показать трехмерное содержимое на вершине мира, как это видно в iPhone или iPad.   Идея состоит в том, чтобы смешать содержимое, поступающее от камеры устройства, с трехмерным содержимым, а также по мере того, как пользователь устройства перемещается по комнате, чтобы обеспечить поведение трехмерного объекта так, чтобы он стал частью этой комнаты. это делается путем привязки объектов к этому миру.

![Анимированная фигура в ARKit](urhosharp-images/image1.gif)

Мы будем использовать библиотеку Урхо для загрузки наших трехмерных ресурсов и размещения их в мире, и мы будем использовать ARKit для получения видеопотока, поступающего от камеры, а также расположения телефона в мире.   По мере того как пользователь переместится по телефону, мы будем использовать изменения в расположении для обновления системы координат, отображаемой ядром Урхо.

Таким образом, при помещении объекта в трехмерное пространство и перемещении пользователя расположение трехмерного объекта отражает место и расположение, куда оно было помещено.

## <a name="setting-up-your-application"></a>Настройка приложения

### <a name="ios-application-launch"></a>Запуск приложения iOS

Приложение iOS должно создать и запустить трехмерное содержимое. для этого нужно создать реализацию подкласса `Urho.Application` и предоставить код установки, `Start` переопределив метод.  В этом случае сцена заполняется данными, обработчики событий — Настройка и т. д.

Мы предоставили `Urho.ArkitApp` класс, который `Urho.Application` подклассы и в `Start` его методе выполняет тяжелую работу.   Все, что нужно сделать для существующего приложения Урхо, — это изменить базовый класс на тип `Urho.ArkitApp` , и у вас есть приложение, которое будет запускать Урхо сцену в мире.

### <a name="the-arkitapp-class"></a>Класс Аркитапп

Этот класс предоставляет набор удобных значений по умолчанию — сцену с некоторыми ключевыми объектами, а также обработка событий ARKit по мере их доставки операционной системой.

Установка выполняется в `Start` виртуальном методе.   При переопределении этого метода в подклассе необходимо создать цепочку для родительского элемента, используя `base.Start()` для своей собственной реализации.

`Start` Метод настраивает сцену, область просмотра, камеру и направленный источник, а также отображает их как открытые свойства:

- Объект `Scene` для хранения объектов,
- направление `Light` с тенями, расположение которых доступно `LightNode` через свойство
- компонент, компоненты которого обновляются, когда ARKit доставляет обновление в приложение и `Camera`
- Объект `ViewPort` , отображающий результаты.

### <a name="your-code"></a>Ваш код

Затем необходимо создать подкласс `ArkitApp` класса и `Start` переопределить метод.   Первое, что должен сделать метод, — это привязка к `ArkitApp.Start` , вызывая. `base.Start()`  После этого можно использовать любую настройку свойств с помощью Аркитапп для добавления объектов в сцену, настройки индикаторов, теней или событий, которые требуется обменять.

Пример ARKit/UrhoSharp загружает анимированный символ с текстурами и воспроизводит анимацию со следующей реализацией:

```csharp
public class MutantDemo : ArkitApp
{
    [Preserve]
    public MutantDemo(ApplicationOptions opts) : base(opts) { }

    Node mutantNode;

    protected override void Start()
    {
        base.Start ();

        // Mutant
        mutantNode = Scene.CreateChild();
        mutantNode.Rotation = new Quaternion(x: 0, y:15, z:0);
        mutantNode.Position = new Vector3(0, -1f, 2f); /*two meters away*/
        mutantNode.SetScale(0.5f);

        var mutant = mutantNode.CreateComponent<AnimatedModel>();
        mutant.Model = ResourceCache.GetModel("Models/Mutant.mdl");
        mutant.Material = ResourceCache.GetMaterial("Materials/mutant_M.xml");

        var animation = mutantNode.CreateComponent<AnimationController>();
        animation.Play("Animations/Mutant_HipHop1.ani", 0, true, 0.2f);
    }
}
```

И это все, что необходимо сделать на этом этапе для отображения трехмерного содержимого в дополненной реальности.

Урхо использует пользовательские форматы для трехмерных моделей и анимаций, поэтому необходимо экспортировать ресурсы в этот формат.   Вы можете использовать такие средства, как [надстройка Urho3D Blend](https://github.com/reattiva/Urho3D-Blender) и [урхоассетимпортер](https://github.com/EgorBo/UrhoAssetImporter) , которые могут преобразовывать эти ресурсы из популярных форматов, таких как dbx, DAE, obj, Blend, 3D-Max, в формат, необходимый Урхо.

Дополнительные сведения о создании трехмерных приложений с помощью Урхо см. в статье [Введение в UrhoSharp](~/graphics-games/urhosharp/introduction.md) Guide.

## <a name="arkitapp-in-depth"></a>Глубина Аркитапп

> [!NOTE]
> Этот раздел предназначен для разработчиков, желающих настроить интерфейс UrhoSharp и ARKit по умолчанию, или вы хотите получить более подробную информацию о принципах интеграции.   Нет необходимости читать этот раздел.

API ARKit довольно прост, вы создаете и настраиваете объект [арсессион](https://developer.apple.com/documentation/arkit/arsession) , который затем запускает доставку объектов [арфраме](https://developer.apple.com/documentation/arkit/arframe) .   Они содержат образ, захваченный камерой, а также предполагаемое реальное расположение устройства.

Мы будем создавать изображения, доставляемые камерой с помощью трехмерного содержимого, и настраивать камеру в UrhoSharp в соответствии с вероятностью расположения и положения устройства.

На следующей схеме показано, что происходит в `ArkitApp` классе:

[![Схема классов и экранов в Аркитапп](urhosharp-images/image2.png)](urhosharp-images/image2.png#lightbox)

### <a name="rendering-the-frames"></a>Подготовка кадров

Идея проста, объедините видео, поступающие из камеры, с помощью трехмерной графики, чтобы создать объединенный образ.     Мы будем получать серию этих захваченных образов последовательно, и мы будем смешивать эти входные данные с помощью сцены Урхо.

Самый простой способ сделать это — вставить `RenderPathCommand` в Main. `RenderPath`  Это набор команд, которые выполняются для рисования одного кадра.  Эта команда заполнит окно просмотра на любую текстуру, которую мы передали.    Мы устанавливаем это на первом кадре, который обрабатывается, и фактическое определение выполняется в файле **аррендерпас. XML** , который загружается в этот момент.

Однако мы столкнулись с двумя проблемами для объединения этих двух миров:


1. В iOS текстуры GPU должны иметь разрешение, которое является степенью двух, но кадры, получаемые от камеры, не имеют разрешения, которые являются степенью числа двух, например: 1280 x 720.
2. Эти кадры кодируются в формате [YUV](https://en.wikipedia.org/wiki/YUV) , представленном двумя изображениями — яркости и чрома.

Кадры YUV имеют два различных решения.  изображение 1280 x 720, представляющее светимость (по сути изображение серого масштаба) и намного меньшее 640 x 360 для компонента чроминанце:

![Изображение, демонстрирующие сочетание компонентов Y и UV](urhosharp-images/image3.png)


Чтобы нарисовать полный цвет изображения с помощью OpenGL ES, нам нужно написать небольшой шейдер, принимающий светимость (компонент Y) и чроминанце (UV плоскости) из слотов текстуры.  В UrhoSharp они имеют имена-"Сдиффмап" и "Снормалмап" и преобразуют их в формат RGB:

```csharp
mat4 ycbcrToRGBTransform = mat4(
    vec4(+1.0000, +1.0000, +1.0000, +0.0000),
    vec4(+0.0000, -0.3441, +1.7720, +0.0000),
    vec4(+1.4020, -0.7141, +0.0000, +0.0000),
    vec4(-0.7010, +0.5291, -0.8860, +1.0000));

vec4 ycbcr = vec4(texture2D(sDiffMap, vTexCoord).r,
                    texture2D(sNormalMap, vTexCoord).ra, 1.0);
gl_FragColor = ycbcrToRGBTransform * ycbcr;
```

Чтобы подготовить текстуру, не имеющую возможностей двух разрешений, необходимо определить Texture2D со следующими параметрами:

```chsarp
// texture for UV-plane;
cameraUVtexture = new Texture2D();
cameraUVtexture.SetNumLevels(1);
cameraUVtexture.SetSize(640, 360, Graphics.LuminanceAlphaFormat, TextureUsage.Dynamic);
cameraUVtexture.FilterMode = TextureFilterMode.Bilinear;
cameraUVtexture.SetAddressMode(TextureCoordinate.U, TextureAddressMode.Clamp);
cameraUVtexture.SetAddressMode(TextureCoordinate.V, TextureAddressMode.Clamp);
```

Таким образом, мы можем визуализировать захваченные изображения в фоновом режиме и визуализировать все сцены над ними, как это страшное мутант.

### <a name="adjusting-the-camera"></a>Настройка камеры

`ARFrame` Объекты также содержат оценочное расположение устройства.  Теперь нам нужно переместить игровую камеру Арфраме — прежде чем ARKit, она не находилась в отслеживании ориентации на устройство (рулон, тон и значения нутации) и выводит закрепленную голограмму поверх видео, но при перемещении устройства Побитовая голограмма будет отменяться.

Это происходит потому, что встроенные датчики, такие как гироскопом, не могут контролировать перемещения, они могут только ускорить.  ARKit анализирует каждый кадр и извлекает точки признаков для контроля и, таким образом, может предоставить нам точную матрицу преобразования, содержащую данные о перемещении и повороте.

Например, можно получить текущее расположение:

```csharp
var row = arCamera.Transform.Row3;
CameraNode.Position = new Vector3(row.X, row.Y, -row.Z);
```

Мы используем `-row.Z` , так как ARKit использует правую систему координат.


### <a name="plane-detection"></a>Обнаружение плоскости

ARKit может обнаруживать горизонтальные плоскости, и эта возможность позволяет взаимодействовать с реальным миром, например, можно разместить мутант на реальной таблице или этаже. Самый простой способ сделать это — использовать метод HitTest (райкастинг). Он преобразует экранные координаты (0,5; 0,5 — центр) в реальные координаты (0; 0; 0 расположение первого кадра).

```chsarp
protected Vector3? HitTest(float screenX = 0.5f, float screenY = 0.5f)
{
    var result = ARSession.CurrentFrame.HitTest(new CGPoint(screenX, screenY),
        ARHitTestResultType.ExistingPlaneUsingExtent)?.FirstOrDefault();
    if (result != null)
    {
        var row = result.WorldTransform.Row3;
        return new Vector3(row.X, row.Y, -row.Z);
    }
    return null;
}
```

Теперь можно разместить мутант на горизонтальной поверхности в зависимости от места на экране устройства, который мы будем коснуться:

```chsarp
void OnTouchEnd(TouchEndEventArgs e)
{
    float x = e.X / (float)Graphics.Width;
    float y = e.Y / (float)Graphics.Height;
    var pos = HitTest(x, y);
    if (pos != null)
    mutantNode.Position = pos.Value;
}
```

![Анимированные фигуры изменение плоскостей при перемещении представлений](urhosharp-images/image4.gif)

### <a name="realistic-lighting"></a>Реалистичное освещение

В зависимости от реальных условий освещения виртуальная сцена должна быть светлее или темнее, чтобы лучше соответствовать окружающей ее среде. Арфраме содержит свойство Лигхтестимате, которое можно использовать для настройки внешнего освещения Урхо. это делается следующим образом:

```csharp
var ambientIntensity = (float) frame.LightEstimate.AmbientIntensity / 1000f;
var zone = Scene.GetComponent<Zone>();
zone.AmbientColor = Color.White * ambientIntensity;
```

### <a name="beyond-ios---hololens"></a>За пределами iOS-HoloLens

UrhoSharp [работает во всех основных операционных системах](~/graphics-games/urhosharp/platform/index.md), поэтому вы можете использовать существующий код в других местах.

HoloLens — одна из самых интересных платформ, на которых он работает.   Это означает, что вы можете легко переключаться между iOS и HoloLens, чтобы создавать потрясающие приложения реальность с помощью UrhoSharp.

Источник Мутантдемо можно найти по адресу [GitHub.com/EgorBo/ARKitXamarinDemo](https://github.com/EgorBo/ARKitXamarinDemo).


## <a name="related-links"></a>Связанные ссылки

- [UrhoSharp](~/graphics-games/urhosharp/index.md)
- [Аркитксамариндемо (с UrhoSharp) (пример)](https://github.com/EgorBo/ARKitXamarinDemo)
